# 无标签远程监督关系抽取研究
# 摘要 
ACE的任务中获得先进效果的关系抽取model依赖于 手动标注的标注语料库进行监督学习得到。该作者提出了一种不依赖于标签语料的替代方法，允许使用任意大小的语料库参与训练，避免了ACE语料训练出的model不够现实的问题。实验使用Freebase--一个包含大量知识和关系三元组的大型语义数据库，可以提供有效的远程监督。对于出现在Freebase中关系中的每对实体，我们有目的性的在大型未标记语料库中提取出含有这些实体的所有句子。并且提取文本特征然后训练一个关系分类器。本文的算法包含了监督关系抽取（IE）（在概率分类器中组合了40万个噪声模式特征）和无监督关系抽取从任意领域的大型语料库中抽取出的大量关系的优点。最终本文的实验中可以以67.7%的精度从1万个实例中提取102类关系。我们同样分析了选取的特征的性能，**表明，句法分析特征对表达模糊不清的和词汇之间距离远的关系非常有用。**  
# Introduce 
从文本中抽取出关系事实的任务主要的方法至少有三种(人-雇佣、地理位置--location)  
监督学习中，首先对句子进行手动标注，以确定是否存在实体以及实体之间的关系。ACE的语料中就是监督学习的良好样本。包含了1000+文档，定义了6类关系类型和一系列的子关系，总共有1w+个关系实例。ACE系统提取各种各样的词汇、句法和语义特征，然后使用分类算法标记。但是监督学习前期语料准备工作成本太高，数量有限，此外一般标记只针对特定的领域，所训练出的分类器也具有领域适用性。  
无监督学习中，在大量文本中提取实体间的字符串，并且尽量的简化这些字符串以产生关系字符串，无监督方法可以使用大量的数据并且提取出大量的关系，但是提取出的关系并不一定能很好的与建设特定知识库所需的关系对齐。  
第三种就是半监督学习，利用较少的种子关系实例或者模式进行引导学习，这些种子与大型的语料库一起使用，提取出新的模式，这些模式再用来提取更多的实例，但是这种模式很容易产生低准确率和语义漂移。  
作者基于上述的问题，提出远程监督方法，其结合了每种方法的优点，最开始，远程监督利用Word-net提取出句子中的is-a关系，并且使用了类似于 weakly labeled生物信息数据。我们的算法使用Freebase提供关系提取的监督数据，Freebase包含了1.16亿个实例中包括了9百万个实体具有7300个关系。  
> **远程监督的直觉解释是：任何包含了Freebase中的实体对的句子都可能以某种方式表达这两个实体之间的关系，也就是说如果Freebase中两个实体之间存在关系，则出现在所有句子中的这两个实体对的句子都以某种形式表达这两个实体之间的关系。**  

> **if two entities have a relationship in a known knowledge base,then all sentences that mention these two entities will express that relationship in some way**    

由于其可能存在非常多的包含给定实体对的句子，所以我们提取大量的特征(其中可能包含噪音)然后结合一个逻辑回归分类器对其进行分类。  
在监督学习中，只能将只有1w多个实例的小范围标记语料作为训练数据，但是该文算法可以使用更多更大量的数据，更多的文本，更多的关系和更多的实例。  
在本文中，共用了120万条wiki百科文章和180多万条实例中的包含10万左右实体的102类关系。另外，在一个大型的分类问题中使用更丰富的特征有助于消除不好的特征所带来的问题。  
本文的做法，实质上是受数据库监督的，并非标签文本，所以其不会遇到困扰监督系统的过拟合和领域依赖性问题·····<点解？？？①>  受数据库监督意味着：不同于无监督方法，分类器可以使用规范的名称来表示关系。  
本文范例提供了一种从多个句子中整合数据的方式来决定两个实体之间的关系。因为我们的算法可以使用大量的未标记数据，所以在测试集中可能会多次出现一对实体，对于每对实体，我们将来自于很多不同句子的特征聚合到一个特征向量中，从而允许我们为分类器提供更多信息，从而生成更加准确的label。  
表1显示了与我们系统提取的关系实例的实例，我们还使用该系统来研究关系抽取中句法与词汇(单词序列)特征的价值。现在已知语法特征可以提高监督学习IE的性能，但是并不知道语法特征对无监督和远程监督关系抽取是否有用。大量的非监督训练都是使用了简单的词法，以节省计算开销。  
# 之前的一些工作
除了无监督算法之外，一般监督和半监督要么针对的数据集较小，要么是将语料分为较少的几类。  
早期算法一般很少使用语法信息，例如基于正则表达式的作者-书籍抽取。  
·······························  
# Freebase  
使用“关系”来表示实体之间的有序的二元关系，我们将这个关系中的个体对称为“关系实例”。例如，人物-国籍关系是实体名称 John和US之间存在关系，所以<John，US>是一个关系实例。我们使用Freebase中的关系和关系实例，Freebase是一个免费的线上结构化语义数据知识库，Freebase的数据来源于各个方面，其中一个主要来源是来自维基百科的文本框和表格数据，数据可以维基百科式的人工编辑，到08年7月，Freebase中包含了9百万个实体之间拥有1.16亿个关系包含了7300个实例。Freebase也包含了很多逆转的关系，这些关系都被合并在一起。过滤和删除最大的关系之外的所有关系，最终拥有了102类关系链接94万实体的180万个关系实例。  
![image](https://note.youdao.com/yws/public/resource/831d6e08c83aac655a96eca3441a6b1d/xmlnote/26DEF38764F949F68EBBBE66BE732A49/6248)  
# 方法  
远程监督的直接解释是用Freebase提供参与标注这些关系的实体对和关系的训练集。在训练过程中使用NER标注器将人、地名、组织等在句子中标识出所有实体。  
**如果一个句子中包含两个实体，并且这些实体是Freebase关系之一的实例，则从该句子中抽取特征，并将该特征添加到这个关系的特征向量中**  
> 远程监督假设是：如果两个实体参与了一个关系，那么任何包含这两个实体的句子都可能表达这种关系。因为任何单个的句子都有可能提供不正确的提示，我们的算法训练一个多分类逻辑回归分类器从嘈杂的特征中学习权重。训练中，组合来自不同句子中的相同元组(关系，实体1，实体2)的特征，创建一个更加丰富的特征。  

> 测试阶段，继续使用NER标注器标注实体，测试的时候，在句子中出现的每对实体都被认为是一个潜在的关系实例，并且当这些这些实体一起出现的时候，在句子上提取出来特征向量并添加到该实体对的特征向量中。例如，如果测试集中的10个句子中都出现了一个实体对，并且一个句子可能提取出3个特征，实体对就将具有30个相关的特征。测试集中每个句子中的每个实体对通过特征提取，并且使用逻辑回归分类器 基于实体对出现的所有的句子中提取的特征来为每对实体对预测关系名称。  

考虑一个关系“位置包含(location-contains)”，在Freebase中我们有两个  这个关系  的关系实例：<Virginia,Richmond>和<France,Nantes>,也就是说：在Freebase中有一个关系，叫location-contains，有两个关系实例在Freebase中。然后，这时候有两个句子：Richmond,the capital of Virginia"和“Henry's Edict of Nantes helped the Protestants of France”,这些句子匹配到了Freebase中的实体对，所以，提取其特征向量。一些特征很有用，例如Richmond句子中的特征，第二个句子中的特征就比较垃圾。在测试的时候，假设输入句子：“Vienna，the capital of Austria”，其一个或多个特征与Richmond句子相匹配，为<Vienna,Austria>属于location-contains提供了证据。  
这个方法的思路的一个主要的优点是它能够结合来自很多相同关系的不同提及方式的信息。考虑实体对<StevenSpielberg, Saving Private Ryan>,从下面两句话中，作为电影-导演（film-director）关系的证据：

```
① [Steven   Spielberg]’s   film   [Saving   PrivateRyan]  
is loosely based on the brothers’ story.  
② Allison  co-produced  the  Academy  Award-winning  
[Saving Private Ryan],  directed by[Steven Spielberg]...
```  
上面句子中的[]应该是已经识别出NER部分。。  
第一句，虽然已经为电影-导演(film-director)提供证据，但也可以为电影-编剧(film-writer)和电影-制片人(film-producer)提供证据。第二句并没有提到 Saving private Ryan是一部电影，可以作为CEO关系的证据(考虑“‘Robert  Mueller  directed  the  FBI’”)
如果单独来看的话，这些特征并不是决定性的，但是组合在一起，就是了。  
# 特征
实验的特征主要选用词汇特征和句法特征。每个特征都基本描述了两个实体是如何在一个句子中相关的，不管是使用句法特征或者非句法特征。
## 词汇特征  
词汇特征描述了出现在实体之间或者周围的特定的词汇。  
+ 两个实体之间的字符串  
+ 单词的词性标注  
+ 指示哪个实体在句子中首次出现的index。  
+ 实体1 的左边的k个词及其词性标注。
+ 实体2 的右边的k个词及其词性标注。  

每个词汇特征都包含了上述几个点提到的组合。针对每个k∈（0,1,2）生成联合特征。表3中每个词表示单个词汇的特征.词性标注由对应的开源工具获得.为了逼近句法特征,作者还测试了词法特征的变化.  
1. 省略所有不是动词的单词
2. 省略掉所有的功能词  

结合其他的词汇特征，它们对精度的影响只有很少的提升，但不足以证明对我们计算资源的需求增加是合理的。   
## 句法特征  
除了词法特征之外，还引入了句法特征。使用对应的句法解析器解析得到。  
依赖解析器，由一组单词和块组成(例如：“Edwin Hubble”，“born”，“Missouri”)，由方向依赖所关联，（例如：“pred”、“mod”等等。对于每个句子，我们提取一对实体之间的依赖路径，依赖路径包含遍历解析的一系列依赖关系、方向和词/块。词性标注不包含在依赖路径里。  
句法特征由以下组成：  
1. 两个实体之间的依赖。  
2. 对于每个实体，一个“window”节点不属于依赖路径。  

window节点是指连接到两个实体其中一个的节点，而不是依赖路径的一部分的节点。我们为每对左窗口节点和右窗口节点生成一个连接特征，以及省略其中一个或者两个特征。[大意应该是设置不同的特征，首先不取窗口词的句法特征、取左边k=1右边k=0的句法特征、。。。。]  
## 命名实体标签特征
除了上面描述的之外，每个特征还应该包含两个实体之间的命名实体标签。该文使用Stanford-nlp来进行NER。
## 特征连接、特征关联 
并不是在分类器中单独的使用以上的每个特征，而是将它们连接在一起。每个特征都包含句子的几个属性的融合，以及命名实体识别标签。要匹配两个特征，它们的关联必须匹配。这会导致召回率低但精度高的情况。数据量较小的时候，这种方法会产生问题，因为大多数特征只出现一次，出现一次的特征对分类器是没有用处的。由于我们使用大量数据，甚至复杂的特征也会出现多次，从而使我们的高精度特征能够按预期工作。一个句子特征的实例像图3中所示。 
# 实验  
## 文本选择  
对于非结构化文本，我们使用Freebase Wikipedia Extraction，这是所有维基百科文章（不包括讨论和用户页面）全文的转储，这些文章由Freebase的开发人员Metaweb Technologies进行了句子标记。这个转储包含大约180万篇文章，每篇文章平均有14.3个句子。单词的总数（计数标点符号）是601,600,703。对于我们的实验，我们使用了大约一半的文章：800,000用于训练，400,000用于测试。我们使用维基百科，因为它是相对最新的，并且因为它的句子倾向于明确许多可能在新闻中被忽略的事实。Freebase中的大部分信息来自维基百科的表格数据，这意味着Freebase关系更可能出现在维基百科的句子中。<fanyi> 
## 解析与分块  
每个句子通过句法解析器从文本中得到依赖图。预处理过程中，具有相同命名实体标记的连续单词会被组块。例如：Edwin/PERSON Hubble/PERSON 变成 [Edwin Hubble]/PERSON。然而，这个组块收到句子依赖解析的限制，因为组块在句法解析中必须是统一的，即实体在句法解析的时候不被拆分。以确保保留解析树结构。  
## 训练和测试 
每个关系的一半的实例并未参与训练，并且在稍后的时候用于比较新发现的实例？？训练中使用了90w个Freebase实例，也保留了90w个未参与训练的实例。这些实验在训练阶段使用了80万的维基百科语料，40万不同的文章用于测试。  
人为评估的实验中，所有的1.8百万关系实例都用来做训练，同样训练阶段使用80万，测试阶段使用40万。本文只提取未出现在训练数据中的关系实例，即Freebase中不存在的实例。  

机器学习系统需要负例训练数据用于训练分类器。再次之前，通过随机选择未出现任何关系中的实体，并对其提取特征，在训练阶段标记为“无关”关系。虽然这些实体对中的一些实际上可能是相关的，但在Freebase数据中被错误地省略，但我们预计这些假负面例子平均会对分类器的性能产生很小的影响。出于性能原因，随机抽取1%的此类实体对作为负面训练实例，相比之下，实际测试数据中，98.7%的实体对并不具备在Freebase中考虑的前102个关系中的任何一个。  


我们使用一个多分类的逻辑回归分类器，使用L-BFGS和高斯正则化进行优化，分类器将一个实体对及其对应的特征向量作为输入，并且返回实体对的关系以及置信度分数，一旦在测试期间发现所有的实体对都被分类，就可以通过置信度评分的方式进行排序，且生成最接近新关系实例的n个列表。  

我们以两种方式评估标签：自动，通过在训练期间保留部分Freebase关系数据，并将新发现的关系实例与这些保留的数据进行比较，手动地让人类查看每个正面标记的实体对并标记是否 这种关系确实存在于参与者之间。 两种评估都允许我们计算最佳N个实例的系统精度  

## held-out评估
图2显示了我们的分类器保持Freebase关系数据的性能。虽然保持 - 评估受到假阴性的影响，但它可以提供精确的测量，而不需要进行昂贵的人工评估，这使得它可以用于参数设置。图中显示说明，词法和句法的组合可以有效的提高特征集的召回率和精度。
## 人为评估  


# 讨论  
我们的研究结果表明，远程监督算法能够提取相当多的关系的高精度模式。  
图2中的结果表明，句法和词汇特征的组合提供了比其自身特征集更好的性能。为了理解句法特征的作用，我们研究了表5，即最常见的10种关系的人体评价。对于每个关系的排名最高的100个实例，大多数最佳结果使用语法特征，单独使用或与词法特征组合使用。对于每个关系的排名最高的1000个实例，结果更加复杂，但语法特征仍然有助于大多数分类。然后我们检查那些句法特征似乎有帮助的关系。 例如，句法特征一直表现为导演电影和作家电影关系的词汇特征。正如第4节所讨论的，这两种关系特别模糊，这表明句法特征可能有助于梳理困难的关系。或许更有说服力，我们注意到了 许多例子在导演和电影之间有很长的一系列文字  
> Back Street is a 1932 film made by Univer-sal Pictures, directed by John M. Stahl, andproduced by Carl Laemmle Jr.  

像这样的句子具有非常长（并且因此罕见）的词汇特征，但相对较短的依赖路径。语法特征可以更容易地从包含这些字符串的外部部分的句法修饰符中抽象出来  
因此，我们的结果表明，句法特征在远程监督的信息提取中确实有用，并且在单个模式特别模糊，并且它们在依赖结构中附近但在术语上相距较远的情况下语法的好处是有用的。。未来的工作仍然是为了看到更简单，基于块的语法特征可能能够在没有完全解析的情况下捕获足够的增益.